{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "> ## Linear methods\n",
    ">>*  Linear Regression\n",
    ">>*  Locally weighted linear regression\n",
    "> ## Non-linear methods\n",
    ">>*  Regression tree\n",
    ">>*  Model tree      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package & Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def loadDataArr(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) - 1\n",
    "    xArr = []; yArr = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr =[]\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        xArr.append(lineArr)\n",
    "        yArr.append(float(curLine[-1]))\n",
    "    return xArr, yArr\n",
    "\n",
    "def loadDataList(fileName):\n",
    "    dataList = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = list(map(float, curLine))      # map data to float()\n",
    "        dataList.append(fltLine)\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdLinReg (dataMat):                    # format the dataset into the target variable Y and the independent variable X\n",
    "    m,n = np.shape(dataMat)\n",
    "    if n == 2:    # only 1D-x and y:  there are only one feature for x, namely no offset column, then add one for the linear regression\n",
    "        X = np.mat(np.ones((m,n)))          # generate ones-matrix\n",
    "        X[:,1:n] = dataMat[:,0:n-1]       # copy feature matrix to X, the 0th-column of matrix X is constant 1 as offset\n",
    "    elif n>2:   # if there are more than one feature for X\n",
    "        X = np.mat(np.ones((m,n-1)))        # generate ones-matrix\n",
    "        X[:,0:n-1] = dataMat[:,0:n-1]       # copy feature matrix to X\n",
    "    else:\n",
    "        raise NameError('no valid input matrix')\n",
    "    Y = np.mat(np.ones((m,1)))        \n",
    "    Y = dataMat[:,-1]                  # copy target matrix to Y\n",
    "    xTx = X.T*X\n",
    "    if np.linalg.det(xTx) == 0.0:                   # check the inversability\n",
    "        raise NameError('This matrix is singular, cannot do inverse,\\n\\\n",
    "        try increasing the second value of Stop Condition')\n",
    "    ws = xTx.I * (X.T * Y)                          # calculate the optimal weight matrix ws with least-squares method\n",
    "    return ws,X,Y\n",
    "\n",
    "\n",
    "def pred_stdLinReg(dataMat_test, wsMat_stdLinReg):\n",
    "    m,n = np.shape(dataMat_test)\n",
    "    if n == 2:    # only 1D-x and y:  there are only one feature for x, namely no offset column, then add one for the linear regression\n",
    "        X = np.mat(np.ones((m,n)))       # generate ones-matrix\n",
    "        X[:,1:n] = dataMat_test[:,0:n-1]       # copy feature matrix to X, the 0th-column of matrix X is constant 1 as offset\n",
    "    elif n>2:   # if there are more than one feature for X\n",
    "        X = np.mat(np.ones((m,n-1)))      # generate ones-matrix\n",
    "        X[:,0:n-1] = dataMat_test[:,0:n-1]      # copy feature matrix to X\n",
    "    else:\n",
    "        raise NameError('no valid input matrix')\n",
    "    \n",
    "    yMat_pred = X * wsMat_stdLinReg\n",
    "    return yMat_pred\n",
    "\n",
    "\n",
    "def showStdLinReg(dataList, yMat_pred=None):\n",
    "    n = len(dataList)                                                    \n",
    "    xcord = []; ycord = []      \n",
    "\n",
    "    if (np.shape(dataList)[1] == 2):            # check the number of columns\n",
    "        for i in range(n):   \n",
    "            xcord.append(dataList[i][0]); ycord.append(dataList[i][1])     # no offset in datalist, so use the first column as x\n",
    "    elif(np.shape(dataList)[1] == 3):           \n",
    "        for i in range(n):   \n",
    "            xcord.append(dataList[i][1]); ycord.append(dataList[i][2])     # the first conlumn is offset, so use the second column as x\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)                                            \n",
    "    ax.scatter(xcord, ycord, s = 20, c = 'blue',alpha = .5)      # plot the orignial data set\n",
    "    if(np.all(yMat_pred != None)):\n",
    "        yArr_pred = yMat_pred[:,0].flatten().A[0]                # convert matrix to array\n",
    "        xMat_test = np.mat(xcord).T          \n",
    "        srtInd = xMat_test.argsort(0)    \n",
    "        xSort  = xMat_test[srtInd][:,0,:]                       # copy the xMat_test in ascending order for pyplot\n",
    "        ax.plot(xSort[:], yArr_pred[srtInd], c = 'red')         # plot the prediction\n",
    "        plt.title('Linear Regression')                             # draw title    \n",
    "    plt.xlabel('X')\n",
    "    plt.show()\n",
    "    \n",
    "def calError(yArr_actual, yArr_pred):                          # calculate the squared error\n",
    "    return ((yArr_actual - yArr_pred) **2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: standard linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList_train = loadDataList(\"./input/trainingData.txt\")         # load the data set\n",
    "showStdLinReg(dataList_train)                  # show graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat_train = np.mat(dataList_train)\n",
    "ws,X,Y = stdLinReg(dataMat_train)                    # calculate the weight for standard linear regression        \n",
    "yMat_pred = pred_stdLinReg(dataMat_train, ws)\n",
    "showStdLinReg(dataList_train, yMat_pred)\n",
    "print(\"correlation coefficients (Origin): \\n\\n\", np.corrcoef(yMat_pred.T, dataMat_train[:,-1].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally weighted linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localWeightLinReg(testPoint, dataMat_train, k = 1.0):       # run lwlr-prediction  on a SINGLE value\n",
    "    m,n = np.shape(dataMat_train)\n",
    "    if n == 2:    # only 1D-x and y:  there are only one feature for x, namely no offset column, then add one for the linear regression\n",
    "        XMat_train = np.mat(np.ones((m,n)))          # generate ones-matrix\n",
    "        XMat_train[:,1:n] = dataMat_train[:,0:n-1]       # copy feature matrix to X, the 0th-column of matrix X is constant 1 as offset\n",
    "    elif n>2:   # if there are more than one feature for X\n",
    "        XMat_train = np.mat(np.ones((m,n-1)))        # generate ones-matrix\n",
    "        XMat_train[:,0:n-1] = dataMat_train[:,0:n-1]       # copy feature matrix to X\n",
    "    else:\n",
    "        raise NameError('no valid input matrix')\n",
    "    YMat_train = np.mat(np.ones((m,1)))        \n",
    "    YMat_train = dataMat_train[:,-1]                  # copy target matrix to Y\n",
    "    \n",
    "    weights = np.mat(np.eye((m)))                          # Create diagonal matrix of weights\n",
    "    for j in range(m):                                     # Populate weights with exponentially decaying values\n",
    "        diffMat = testPoint - XMat_train[j,:]                                 \n",
    "        weights[j, j] = np.exp(diffMat * diffMat.T/(-2.0 * k**2))     # locally weighted     \n",
    "    xTx = XMat_train.T * (weights * XMat_train)                                        \n",
    "    if np.linalg.det(xTx) == 0.0:                                     # test the inversability\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = xTx.I * (XMat_train.T * (weights * YMat_train))               # calculate the weights for \"Locally weighted linear regression\"\n",
    "    return testPoint * ws   \n",
    "\n",
    "def lwlr_Test(dataMat_test, dataMat_train, k=1.0):     # run lwlr-prediction  on a test ARRAY\n",
    "    m,n = np.shape(dataMat_test)\n",
    "    if n == 2:                                      # only 1D-x and y:  there are only one feature for x, namely no offset column, then add one for the linear regression\n",
    "        Xmat_test = np.mat(np.ones((m,n)))          # generate ones-matrix\n",
    "        Xmat_test[:,1:n] = dataMat_test[:,0:n-1]    # copy feature matrix to X, the 0th-column of matrix X is constant 1 as offset\n",
    "    elif n>2:                                       # if there are more than one feature for X\n",
    "        Xmat_test = np.mat(np.ones((m,n-1)))        # generate ones-matrix\n",
    "        Xmat_test[:,0:n-1] = dataMat_test[:,0:n-1]       # copy feature matrix to X\n",
    "    else:\n",
    "        raise NameError('no valid input matrix')\n",
    "    \n",
    "    yArr_pred = np.zeros(m)    \n",
    "    for i in range(m):                                       # predict for each single element of test array\n",
    "        yArr_pred[i] = localWeightLinReg(Xmat_test[i], dataMat_train, k)\n",
    "    return yArr_pred\n",
    "\n",
    "def showLwlr(dataList, yArr_pred=None, k=1.0):\n",
    "    n = len(dataList)                                                    \n",
    "    xcord = []; ycord = []      \n",
    "\n",
    "    if (np.shape(dataList)[1] == 2):            # check the number of columns\n",
    "        for i in range(n):   \n",
    "            xcord.append(dataList[i][0]); ycord.append(dataList[i][1])     # no offset in datalist, so use the first column as x\n",
    "    elif(np.shape(dataList)[1] == 3):           \n",
    "        for i in range(n):   \n",
    "            xcord.append(dataList[i][1]); ycord.append(dataList[i][2])     # the first conlumn is offset, so use the second column as x\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)                                 # create subplot   \n",
    "    ax.scatter(xcord, ycord, s = 20, c = 'blue',alpha = .5)      # plot the orignial data set\n",
    "    if(np.all(yArr_pred != None)):\n",
    "        xMat_test = np.mat(xcord).T          \n",
    "        srtInd = xMat_test.argsort(0)    \n",
    "        xSort  = xMat_test[srtInd][:,0,:]                       # copy the xMat_test in ascending order for pyplot\n",
    "        ax.plot(xSort[:], yArr_pred[srtInd], c = 'red')         # plot the prediction\n",
    "        plt.title('Locally weighted linear regression, k={}'.format(k))     # draw title    \n",
    "    plt.xlabel('X')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Locally weighted linear regression with K = 1, 0.05, 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yArr_pred = lwlr_Test(dataMat_train, dataMat_train, k = 1)\n",
    "showLwlr(dataList_train, yArr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yArr_pred = lwlr_Test(dataMat_train, dataMat_train, k = 0.05)\n",
    "showLwlr(dataList_train, yArr_pred, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yArr_pred = lwlr_Test(dataMat_train, dataMat_train, k = 0.005)\n",
    "showLwlr(dataList_train, yArr_pred, k=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: predicting the age of an abalone with \n",
    "* standard linear regression \n",
    "* locally weighted linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList_train = loadDataList('./input/abalone.txt');  dataMat_train = np.mat(dataList_train)\n",
    "xArr_org, yArr_org = loadDataArr('./input/abalone.txt')\n",
    "print(\"xArr_org[0:5]:\\n\",np.reshape(xArr_org[0:5],(5,-1)))\n",
    "print(\"yArr_org[0:5]:\\n\",np.reshape(yArr_org[0:5],(5,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yArr_pred_01 = lwlr_Test(dataMat_train[0:99,:], dataMat_train[0:99,:], k=0.1)\n",
    "yArr_pred_1  = lwlr_Test(dataMat_train[0:99,:], dataMat_train[0:99,:], k=1)\n",
    "yArr_pred_10 = lwlr_Test(dataMat_train[0:99,:], dataMat_train[0:99,:], k=10)\n",
    "print('Training set and test set are identical, the effects of kernel on the estimates are:')\n",
    "print('for k=0.1, the Error (Origin):',calError(dataMat_train[0:99,-1].flatten().A[0].tolist(), yArr_pred_01.T))\n",
    "print('for k=1,   the Error (Origin):',calError(dataMat_train[0:99,-1].flatten().A[0].tolist(), yArr_pred_1.T))\n",
    "print('for k=10,  the Error (Origin):',calError(dataMat_train[0:99,-1].flatten().A[0].tolist(), yArr_pred_10.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yArr_pred_01 = lwlr_Test(dataMat_train[100:199,:], dataMat_train[0:99,:], k=0.1)\n",
    "yArr_pred_1  = lwlr_Test(dataMat_train[100:199,:], dataMat_train[0:99,:], k=1)\n",
    "yArr_pred_10 = lwlr_Test(dataMat_train[100:199,:], dataMat_train[0:99,:], k=10)\n",
    "print('Training set and test set are different, the effects of kernel on the estimates are:')\n",
    "print('for k=0.1, the Error (Test):',calError(dataMat_train[100:199,-1].flatten().A[0].tolist(), yArr_pred_01.T))\n",
    "print('for k=1,   the Error (Test):',calError(dataMat_train[100:199,-1].flatten().A[0].tolist(), yArr_pred_1.T))\n",
    "print('for k=10,  the Error (Test):',calError(dataMat_train[100:199,-1].flatten().A[0].tolist(), yArr_pred_10.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set and test set are different, linear regression vs. locally weighted linear regression with k=1:')\n",
    "print('lwlr with k=1, the Error (Test):', calError(dataMat_train[100:199,-1].flatten().A[0].tolist(), yArr_pred_1.T))\n",
    "ws,X,Y = stdLinReg(dataMat_train[0:99,:])   \n",
    "yMat_pred = pred_stdLinReg(dataMat_train[100:199,:], ws)\n",
    "print('linear regression, the Error (Test):', calError(dataMat_train[100:199,-1].flatten().A[0].tolist(), yMat_pred.T.A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def showTree(dataList, yArr_pred=None, mode=\"regTree\"):\n",
    "    n = len(dataList)                                                    \n",
    "    xcord = []; ycord = []      \n",
    "\n",
    "    if (np.shape(dataList)[1] == 2):            # check the number of columns\n",
    "        for i in range(n):   \n",
    "            xcord.append(dataList[i][0]); ycord.append(dataList[i][1])    \n",
    "    elif(np.shape(dataList)[1] == 3):\n",
    "        for i in range(n):   \n",
    "            xcord.append(dataList[i][1]); ycord.append(dataList[i][2])    \n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)                                            \n",
    "    ax.scatter(xcord, ycord, s = 20, c = 'blue',alpha = .5)      # plot the orignial data set\n",
    "    if(np.all(yArr_pred != None)):\n",
    "        xMat_test = np.mat(xcord).T          \n",
    "        srtInd = xMat_test.argsort(0)    \n",
    "        xSort  = xMat_test[srtInd][:,0,:]                       # copy the xMat_test in ascending order for pyplot\n",
    "        ax.plot(xSort[:], yArr_pred[srtInd], c = 'red')         # plot the prediction\n",
    "    if(mode == \"regTree\"):\n",
    "        plt.title('Regression  Tree')         \n",
    "    elif(mode == \"modTree\"):\n",
    "        plt.title('Model  Tree')  \n",
    "    plt.xlabel('X')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "##########################   functions for building Regression Tree    ##########################\n",
    "\n",
    "def regLeaf(dataMat):                      # calculate the MEAN value as the model for a Leaf node\n",
    "    return np.mean(dataMat[:,-1])          # dataMat[:,-1]: the last column of dataMat is Y\n",
    "\n",
    "def regErr(dataMat):                       # calculate the TOTAL Squared Error of the target variables in a given dataset\n",
    "    return np.var(dataMat[:,-1]) * np.shape(dataMat)[0]            # var(x): mean((x_i - x.mean())**2)\n",
    "    # the smaller the variance is, the better the split. Goal: try to use LEAST split to seperate the whole data set\n",
    "\n",
    "##########################   functions for building Model Tree    ##############################\n",
    "\n",
    "def linearSolve(dataMat):  # format the dataset into the target variable Y and the independent variable X\n",
    "    m,n = np.shape(dataMat)\n",
    "    X = np.mat(np.ones((m,n))); Y = np.mat(np.ones((m,1)))      # generate ones-matrix\n",
    "    X[:,1:n] = dataMat[:,0:n-1];       # copy feature matrix to X, the 0th-column of matrix X is constant 1 as offset\n",
    "    Y = dataMat[:,-1]                  # copy target matrix to Y\n",
    "    xTx = X.T*X\n",
    "    if np.linalg.det(xTx) == 0.0:                   # check the inversability\n",
    "        raise NameError('This matrix is singular, cannot do inverse,\\n\\\n",
    "        try increasing the second value of Stop Condition')\n",
    "    ws = xTx.I * (X.T * Y)                          # calculate the optimal weight matrix ws with least-squares method\n",
    "    return ws,X,Y\n",
    "\n",
    "\n",
    "def modelLeaf(dataMat):                             # generate a model for a leaf node\n",
    "    ws,X,Y = linearSolve(dataMat)\n",
    "    return ws\n",
    "\n",
    "def modelErr(dataMat):                              # calculate the total squared error \n",
    "    ws,X,Y = linearSolve(dataMat)                   # of model against target\n",
    "    yHat = X * ws\n",
    "    return sum(np.power(Y - yHat, 2))        \n",
    "\n",
    "\n",
    "##########################   functions for split    ##############################\n",
    "\n",
    "def binSplitDataSet(dataMat, feature, value):                          # binary split\n",
    "    mat0 = dataMat[np.nonzero(dataMat[:,feature] <= value)[0],:]       # np.nonzero(dataMat[:,feature] <= value)[0]: return index of target rows\n",
    "    mat1 = dataMat[np.nonzero(dataMat[:,feature] > value)[0],:]        # np.nonzero(dataMat[:,feature] > value)[0]: return index of target rows\n",
    "    return mat0, mat1\n",
    "\n",
    "def chooseBestSplit(dataMat, leafType = regLeaf, errType = regErr, stopCond = (1,4)):\n",
    "    minErrReduction = stopCond[0];         # stop condition: minimal Error reduction should be made through a new split\n",
    "    minInstance = stopCond[1]              # stop condition: minimal amount of instances should be included in a leaf node\n",
    "    if len(set(dataMat[:,-1].T.tolist()[0])) == 1:     # If all y-values are equal, NO SPLIT: Leaf node\n",
    "        return None, leafType(dataMat)                 # calculate value for leaf node  \n",
    "    \n",
    "    m, n = np.shape(dataMat)      # get the size of dataset\n",
    "    preError = errType(dataMat)   # setting the last feature as the best split and estimate its error for further compare\n",
    "    bestError = float('inf');     # initialize bestError as an infinite value\n",
    "    bestIndex = 0;                # initialize best splitting feature(Index) \n",
    "    bestValue = 0                 # initialize best splitting value\n",
    "  \n",
    "    for featIndex in range(n - 1):   # iterate all feature columns to find the splitting feature and splitting value\n",
    "        for splitVal in set(dataMat[:,featIndex].T.tolist()[0]):    # iterate all x-values of ONE certain feature\n",
    "            mat0, mat1 = binSplitDataSet(dataMat, featIndex, splitVal) \n",
    "            if (np.shape(mat0)[0] < minInstance) or (np.shape(mat1)[0] < minInstance): continue  # stop conditions met, NO SPLIT: Leaf node\n",
    "            newError = errType(mat0) + errType(mat1)      # calculate the new error from two split sets\n",
    "            if newError < bestError:                      # update if new error is smaller than best error\n",
    "                bestIndex = featIndex\n",
    "                bestValue = splitVal\n",
    "                bestError = newError\n",
    "                \n",
    "    if (preError - bestError) < minErrReduction:                 # If stop conditions met, NO SPLIT: leaf node\n",
    "        return None, leafType(dataMat)                           # calculate value for leaf node\n",
    "    \n",
    "    mat0, mat1 = binSplitDataSet(dataMat, bestIndex, bestValue)   # otherweise make the best split\n",
    "    if (np.shape(mat0)[0] < minInstance) or (np.shape(mat1)[0] < minInstance):  # If stop conditions met, NO SPLIT: leaf node\n",
    "        return None, leafType(dataMat)                            # calculate value for leaf node  \n",
    "    return bestIndex, bestValue\n",
    "\n",
    "\n",
    "##########################   functions for Creating and Pruning tree    ##############################\n",
    "\n",
    "def createTree(dataMat_train, leafType = regLeaf, errType = regErr, stopCond = (1, 4)):\n",
    "    feat, val = chooseBestSplit(dataMat_train, leafType, errType, stopCond)\n",
    "    if feat == None: return val        # If stop condition met, return leaf value for the leaf node \n",
    "    retTree = {}                       # define retTree as dictionary\n",
    "    retTree['spFeatIndex'] = feat\n",
    "    retTree['spValue'] = val\n",
    "    left_Set, right_Set = binSplitDataSet(dataMat_train, feat, val)\n",
    "    retTree['left'] = createTree(left_Set, leafType, errType, stopCond)\n",
    "    retTree['right'] = createTree(right_Set, leafType, errType, stopCond)\n",
    "    return retTree  \n",
    "\n",
    "def isTree(obj):      # check whether it is a tree or a leaf node\n",
    "    return (type(obj).__name__ == 'dict') \n",
    " \n",
    "\n",
    "def getMean(tree):    # descend a tree untill it hits only leaf nodes, then take the MEAN value of both\n",
    "    if isTree(tree['right']): \n",
    "        tree['right'] = getMean(tree['right'])\n",
    "    if isTree(tree['left']): \n",
    "        tree['left'] = getMean(tree['left'])\n",
    "    return (tree['left'] + tree['right']) / 2.0    \n",
    "\n",
    "\n",
    "def prune(tree, testData):            # Post-pruning\n",
    "    if np.shape(testData)[0] == 0:    # If no test data return MEAN value of left and right nodes \n",
    "        return getMean(tree)  \n",
    "    \n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):  # split test data according to the trained tree\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spFeatIndex'], tree['spValue'])\n",
    "    if isTree(tree['left']): \n",
    "        tree['left'] = prune(tree['left'], lSet)      # prune the left subtree\n",
    "    if isTree(tree['right']): \n",
    "        tree['right'] = prune(tree['right'], rSet)    # prune the right subtree\n",
    "    if not isTree(tree['left']) and not isTree(tree['right']):     # if the leaf node of trained tree is reached\n",
    "        \n",
    "        #  test the total squared error with the value of leaf node of trained tree\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spFeatIndex'], tree['spValue']) \n",
    "        errorNoMerge = np.sum(np.power(lSet[:,-1] - tree['left'], 2)) + np.sum(np.power(rSet[:,-1] - tree['right'], 2))\n",
    "\n",
    "        #  test the total squared error with the MEAN value of leaf node of trained tree\n",
    "        treeMean = (tree['left'] + tree['right']) / 2.0\n",
    "        errorMerge = np.sum(np.power(testData[:,-1] - treeMean, 2))\n",
    "        \n",
    "        if errorMerge < errorNoMerge: \n",
    "  #          print(\"merging, tree['spFeatIndex']: {}, tree['spValue']:{}, tree['left']:{}, tree['right']:{}\".format(tree['spFeatIndex'],tree['spValue'],tree['left'],tree['right']))\n",
    "  #          print(\"treeMean:\", treeMean)\n",
    "  #          print(\"\\n\")\n",
    "            return treeMean             # MERGE the left and right leaf node into one leaf node with MEAN value\n",
    "        else: \n",
    "            return tree\n",
    "    else: \n",
    "        return tree\n",
    "    \n",
    "    \n",
    "    \n",
    "##########################   functions for Prediction with Tree Model    ##############################\n",
    "\n",
    "def regTreeEval(model, inDat):     # evaluate a Regression Tree leaf node\n",
    "    return float(model)            # return the value at the leaf node\n",
    "\n",
    "\n",
    "def modelTreeEval(model, inDat):   # evaluate a Model Tree leaf node\n",
    "    n = np.shape(inDat)[1]\n",
    "    X = np.mat(np.ones((1, n+1)))  # n+1 features, including the offset\n",
    "    X[:, 1: n+1] = inDat           # copy inDat to X second to (n+1)th. column, X first column is offset with value '1'\n",
    "    return float(X * model)        # return the forecasted value\n",
    "\n",
    "\n",
    "def treeForecast(tree_trained, dataMat_test, modelEval=regTreeEval):  # give one forecast for one data point, for a given tree.\n",
    "\n",
    "    if not isTree(tree_trained):                                # when a leaf node is hit, run modelEval()\n",
    "        return modelEval(tree_trained, dataMat_test)\n",
    "    \n",
    "    if dataMat_test[:,tree_trained['spFeatIndex']] <= tree_trained['spValue']:    # follow the tree based on the input data \n",
    "        if isTree(tree_trained['left']):                                          # until a leaf node is hit \n",
    "            return treeForecast(tree_trained['left'], dataMat_test, modelEval)\n",
    "        else:\n",
    "            return modelEval(tree_trained['left'], dataMat_test)\n",
    "    else:\n",
    "        if isTree(tree_trained['right']):\n",
    "            return treeForecast(tree_trained['right'], dataMat_test, modelEval)\n",
    "        else:\n",
    "            return modelEval(tree_trained['right'], dataMat_test)\n",
    "        \n",
    "        \n",
    "def createForeCast(tree_trained, dataMat_test, modelEval=regTreeEval):\n",
    "    m = len(dataMat_test)\n",
    "    yArr_pred = np.zeros(m)\n",
    "    for i in range(m):                        #  run prediction for each SINGLE value of test set\n",
    "        yArr_pred[i] = treeForecast(tree_trained, np.mat(dataMat_test[i]), modelEval)\n",
    "    return yArr_pred\n",
    "\n",
    "\n",
    "##########################   functions for plotting the tree    ##############################\n",
    "\n",
    "def getNumLeafs(tree, numLeafNode=0):\n",
    "   \n",
    "    if isTree(tree['left']):       # check the 'left' part, whether it is a leaf node already\n",
    "        numLeafNode = getNumLeafs(tree['left'], numLeafNode)\n",
    "    else:\n",
    "        numLeafNode += 1           # 'left' is a leaf node,then increment the total number of leaf node and then  check the 'right' of the SAME level!\n",
    "    if isTree(tree['right']):      # check the 'right' of the SAME level\n",
    "        numLeafNode = getNumLeafs(tree['right'], numLeafNode)\n",
    "    else:\n",
    "        return numLeafNode + 1     # if it is a lefe node, then return to the last stage\n",
    "    \n",
    "    return numLeafNode\n",
    "\n",
    "\n",
    "def getDepth(tree, numTreeDepth=0, max =0):\n",
    "    \n",
    "    if not isTree(tree): \n",
    "        return 0\n",
    "    if isTree(tree['left']):       # check the 'left' part, whether it is a tree \n",
    "        max = getDepth(tree['left'], numTreeDepth + 1, max)     # it is a tree, then go deep\n",
    "    if isTree(tree['right']):      # check the 'right' of the SAME level\n",
    "        max = getDepth(tree['right'], numTreeDepth + 1, max)\n",
    "    else:\n",
    "        numTreeDepth += 1\n",
    "    max = numTreeDepth if numTreeDepth >= max else max\n",
    "    return max             # return to the last stage\n",
    "\n",
    "def getTreeDepth(tree):\n",
    "    leftDepth = getDepth(tree['left'])\n",
    "    rightDepth = getDepth(tree['right'])\n",
    "    treeDepth = leftDepth if leftDepth >= rightDepth else rightDepth\n",
    "    return treeDepth+1              # plus the very first splitt\n",
    "\n",
    "###########################################################################################\n",
    "###########################################################################################\n",
    "\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):                              #   plot comment with arrow\n",
    "    arrow_args = dict(arrowstyle=\"<-\")                                            # set arrow format\n",
    "#    font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)         # set chinese fond\n",
    "    createPlot.ax1.annotate(nodeTxt, xy=parentPt,  xycoords='axes fraction',      # plot node\n",
    "        xytext=centerPt, textcoords='axes fraction',\n",
    "        va=\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args)\n",
    "        \n",
    "\n",
    "def plotMidText(cntrPt, parentPt, txtString):                                     #   plot transfer information bewteen tree and subtree\n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]                                # calculate position                  \n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]\n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\", rotation=30)\n",
    "    \n",
    "###########################################################################################\n",
    "\n",
    "def plotTree(myTree, parentPt, nodeTxt, factorX=1, factorY=1):\n",
    "    decisionNode = dict(boxstyle=\"sawtooth\", fc=\"0.8\")      # set decision node format，frame and arrow\n",
    "    leafNode = dict(boxstyle=\"round4\", fc=\"0.8\")            # set leaf node format\n",
    "    numLeafs = getNumLeafs(myTree)                          # get current number of total leaf nodes\n",
    "#    depth = getTreeDepth(myTree)                           # get depth of tree\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)      #  define center position\n",
    "\n",
    "##### plot decision node by plotNode(nodeTxt, centerPt, parentPt, nodeType)\n",
    "    spFeatIndex = myTree['spFeatIndex']  \n",
    "    spValue =  round(myTree['spValue'],2)                     # get the splitting point\n",
    "    plotMidText(cntrPt, parentPt, '')\n",
    "    plotNode(\"Feat:\"+ str(spFeatIndex)+\"\\n\"+\"Val: \" + str(spValue), cntrPt,  parentPt, decisionNode) \n",
    "    \n",
    "#####  check leaf node\n",
    "    if isTree(myTree['left']):                                          # if the leaf node is a tree, then run plotTree function\n",
    "        plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD  #*factorY     # update yOff for leaf node\n",
    "        plotTree(myTree['left'], cntrPt, '', factorX, factorY)\n",
    "    else:                                                               # if the leaf node is a leaf node, then plot the node\n",
    "        plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW             # update xOff for leaf node  !!!!!!!!\n",
    "        plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD  #*factorY     # update yOff for leaf node\n",
    "        leftNode = round(myTree['left'],2)                              # calculate value for leaf node\n",
    "        plotNode(str(leftNode), (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)      # plot left node\n",
    "        plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, \"<=\")                      # add \"<=\" \n",
    "        \n",
    "    if isTree(myTree['right']):                                         # if the leaf node is a tree, then run plotTree function\n",
    "        plotTree(myTree['right'], cntrPt, '', factorX, factorY)\n",
    "    else:                                                               # if the leaf node is a leaf node, then plot the node\n",
    "        plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW             # update xOff for leaf node\n",
    "        rightNode = round(myTree['right'],2)                            # calculate value for leaf node\n",
    "        plotNode(str(rightNode), (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)      # plot left node\n",
    "        plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, \">\")                        # add \"<=\" \n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD #*factorY                         # go back to the last stage   \n",
    "    \n",
    "    \n",
    "def createPlot(inTree,  factorX=1, factorY=1):\n",
    "    fig = plt.figure(1, facecolor='white')                                                  # create fig\n",
    "    fig.clf()                                                                               # clear fig\n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)                             # delete x、y轴\n",
    "    sumLeafNodes = getNumLeafs(inTree)\n",
    "    treeDepth = getTreeDepth(inTree)\n",
    "    plotTree.totalW = float(getNumLeafs(inTree))/factorX                                    # get total numbe of leaf nodes\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))/factorY                                           # get depth of tree\n",
    "    plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0;                              # define offset for x, y\n",
    "    parent = (plotTree.xOff + (1.0 + float(getNumLeafs(inTree)))/2.0/plotTree.totalW, plotTree.yOff) \n",
    "    print(\"Sum of leaf nodes: {} \\tTree depth: {} \\t\\tfactorX: {}\\tfactorY: {}\".format(sumLeafNodes, treeDepth,factorX, factorY))\n",
    "    plotTree(inTree, parent, '', factorX, factorY)                                       # plot tree\n",
    "    plt.show()       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 1\n",
    "showTree(loadDataList(\"./input/data1.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 1\n",
    "dataList = loadDataList(\"./input/data1.txt\")\n",
    "dataMat = np.mat(dataList)\n",
    "tree_trained = createTree(dataMat)\n",
    "yArr_pred = createForeCast(tree_trained, dataMat[:,0])\n",
    "createPlot(tree_trained)\n",
    "showTree(dataList, yArr_pred)\n",
    "print(\"Regression tree: \", tree_trained)\n",
    "print(\"\\ncorrelation coefficients (Origin)): \", np.corrcoef(yArr_pred, dataMat[:,1], rowvar=0)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 2\n",
    "showTree(loadDataList(\"./input/data2.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 2\n",
    "dataList = loadDataList(\"./input/data2.txt\")\n",
    "dataMat = np.mat(dataList)\n",
    "tree_trained = createTree(dataMat)\n",
    "yArr_pred = createForeCast(tree_trained, dataMat[:,:-1])\n",
    "createPlot(tree_trained)\n",
    "showTree(dataList, yArr_pred)\n",
    "print(\"Regression tree: \", tree_trained)\n",
    "print(\"\\ncorrelation coefficients (Origin): \", np.corrcoef(yArr_pred, dataMat[:,2], rowvar=0)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 3 (TRAIN)\n",
    "showTree(loadDataList(\"./input/data3.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 3 (TRAIN, stopcondition(1,4))\n",
    "dataList = loadDataList(\"./input/data3.txt\")\n",
    "dataMat = np.mat(dataList)\n",
    "tree_trained = createTree(dataMat, stopCond=(1,4))\n",
    "yArr_pred = createForeCast(tree_trained, dataMat[:,0])\n",
    "createPlot(tree_trained,4,2)\n",
    "showTree(dataList, yArr_pred)\n",
    "print(\"correlation coefficients (Origin): \", np.corrcoef(yArr_pred, dataMat[:,1], rowvar=0)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 3 (TRAIN, stopcondition(10000,4))\n",
    "tree_trained = createTree(dataMat, stopCond=(10000,4))\n",
    "yArr_pred = createForeCast(tree_trained, dataMat[:,0])\n",
    "createPlot(tree_trained)\n",
    "showTree(dataList, yArr_pred)\n",
    "print(\"correlation coefficients (Origin): \", np.corrcoef(yArr_pred, dataMat[:,1], rowvar=0)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postpruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 3 (TEST)\n",
    "showTree(loadDataList(\"./input/data3test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 3 (TEST, stop condition(0,1), Prepruning)\n",
    "dataList_train = loadDataList(\"./input/data3.txt\");    dataMat_train = np.mat(dataList_train)\n",
    "dataList_test = loadDataList(\"./input/data3test.txt\"); dataMat_test = np.mat(dataList_test)\n",
    "\n",
    "prePruningTree = createTree(dataMat_train, stopCond=(0,1))                # built the Biggest tree with stopCond(0,1)\n",
    "yArr_prePrun = createForeCast(prePruningTree, dataMat_train[:,0])         # predition on the TRAIN file\n",
    "print(\"Before Post-pruning:\")\n",
    "createPlot(prePruningTree,5,2)\n",
    "showTree(dataList_train, yArr_prePrun)\n",
    "\n",
    "yArr_prePrun = createForeCast(prePruningTree, dataMat_test[:,0])           # predition with prePruningTree on TEST file\n",
    "print(\"Before Post-pruning:\")\n",
    "print(\"\\ncorrelation coefficients (Test): \", np.corrcoef(yArr_prePrun, dataMat_test[:,1], rowvar=0)[0,1])\n",
    "print(\"\\nSquared error (Test): \", calError(dataMat_test[:,1].flatten().A[0], yArr_prePrun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##   Regression tree: Data 3 (TEST, stop condition(0,1), Postpruning)\n",
    "postPruningTree = prune(prePruningTree, dataMat_test)                       # Postpruning with test file\n",
    "yArr_postPrun = createForeCast(postPruningTree, dataMat_train[:,0])         # predition on the TRAIN file\n",
    "print(\"After Post-pruning:\\n\")\n",
    "createPlot(postPruningTree,5,2)\n",
    "showTree(dataList_train, yArr_postPrun)\n",
    "\n",
    "\n",
    "yArr_postPrun = createForeCast(postPruningTree, dataMat_test[:,0])         # predition with postPruningTree on TEST file\n",
    "print(\"After Post-pruning:\\n\")\n",
    "print(\"correlation coefficients (Test): \", np.corrcoef(yArr_postPrun, dataMat_test[:,1], rowvar=0)[0,1])\n",
    "print(\"\\nSquared error (Test): \", calError(dataMat_test[:,1].flatten().A[0], yArr_postPrun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/data4.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0e0e52962e8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##   Model tree: Data 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshowTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadDataList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./input/data4.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-a82aecf1b8f2>\u001b[0m in \u001b[0;36mloadDataList\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadDataList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdataList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mcurLine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/data4.txt'"
     ]
    }
   ],
   "source": [
    "##   Model tree: Data 4 \n",
    "showTree(loadDataList(\"./input/data4.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/data4.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c7800cbd4c41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##   Model tree: Data 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDataList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./input/data4.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdataMat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtree_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelLeaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelErr\u001b[0m\u001b[1;33m)\u001b[0m                        \u001b[1;31m# built the Biggest tree !!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myArr_prePrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateForeCast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_trained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataMat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelTreeEval\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# predition based on Model Tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-a82aecf1b8f2>\u001b[0m in \u001b[0;36mloadDataList\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadDataList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdataList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mcurLine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/data4.txt'"
     ]
    }
   ],
   "source": [
    "##   Model tree: Data 4 \n",
    "dataList = loadDataList(\"./input/data4.txt\")\n",
    "dataMat = np.mat(dataList)\n",
    "tree_trained = createTree(dataMat, modelLeaf, modelErr)                        # built the Biggest tree !!!\n",
    "yArr_prePrun = createForeCast(tree_trained, dataMat[:,0], modelTreeEval)       # predition based on Model Tree\n",
    "showTree(dataList, yArr_prePrun, mode = \"modTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree regression vs. Standand linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show the train and test data\n",
    "dataList_train = loadDataList(\"./input/bikeSpeedVsIq_train.txt\"); dataMat_train = np.mat(dataList_train)\n",
    "dataList_test = loadDataList(\"./input/bikeSpeedVsIq_test.txt\"); dataMat_test = np.mat(dataList_test)\n",
    "showStdLinReg(dataList_train)     \n",
    "showStdLinReg(dataList_test)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Linear Regression: \\n\")\n",
    "wsMat_stdLinReg, xMat_train, yMat_train = stdLinReg(dataMat_train)                     \n",
    "yMat_train_predLinReg = pred_stdLinReg(dataMat_train, wsMat_stdLinReg)\n",
    "showStdLinReg(dataList_train, yMat_train_predLinReg)                 \n",
    "\n",
    "yMat_test_predLinReg = pred_stdLinReg(dataMat_test, wsMat_stdLinReg)\n",
    "print(\"Correlation coefficients (Test): \", np.corrcoef(yMat_test_predLinReg.T, dataMat_test[:,-1].T, rowvar=0)[0,1])\n",
    "print('\\nSquared error (Test): ', calError(dataMat_test[:,-1].flatten().A[0].tolist(), yMat_test_predLinReg.T.A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression tree: \\n\")\n",
    "tree_trained = createTree(dataMat_train, stopCond=(1,20))\n",
    "yArr_pred_train = createForeCast(tree_trained, dataMat_train[:,0])\n",
    "showTree(dataList_train, yArr_pred_train)\n",
    "\n",
    "yArr_pred_test = createForeCast(tree_trained, dataMat_test[:,0])\n",
    "print(\"Regression tree: \\n\")\n",
    "print(\"correlation coefficients (Test): \", np.corrcoef(yArr_pred_test, dataMat_test[:,1], rowvar=0)[0,1])\n",
    "print(\"\\nSquared error (Test): \", calError(dataMat_test[:,1].flatten().A[0], yArr_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model tree: \\n\")\n",
    "tree_trained = createTree(dataMat_train, modelLeaf, modelErr, stopCond=(1, 20))\n",
    "yArr_pred_train = createForeCast(tree_trained, dataMat_train[:,0], modelTreeEval)\n",
    "showTree(dataList_train, yArr_pred_train, mode = \"modTree\")\n",
    "\n",
    "yArr_pred_test = createForeCast(tree_trained, dataMat_test[:,0], modelTreeEval)\n",
    "print(\"Model tree: \\n\")\n",
    "print(\"correlation coefficients (Test): \", np.corrcoef(yArr_pred_test, dataMat_test[:,1], rowvar=0)[0,1])\n",
    "print(\"\\nSquared error (Test): \", calError(dataMat_test[:,1].flatten().A[0], yArr_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
